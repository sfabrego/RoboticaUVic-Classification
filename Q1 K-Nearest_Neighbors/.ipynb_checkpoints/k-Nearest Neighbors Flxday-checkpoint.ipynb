{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#k-Nearest Neighbors\n",
      "\n",
      "#Q1 Implementar una funci\u00f3n que hace la clasificaci\u00f3n kNN,y lo utilizan para clasificar el conjunto de datos del iris. \n",
      "#Una vez que obtenga una clasificaci\u00f3n casi perfecta all\u00ed, utilice su funci\u00f3n en el conjunto de datos 3DClothing. \n",
      "#Trace la exactitud para todos los valores impares de k de 1 a 9.\n",
      "\n",
      "#Q1 Implement a function that does kNN classification, and use it to classify the Iris dataset. \n",
      "#Once you get a near-perfect classification there, use your function in the 3DClothing dataset. \n",
      "#Plot the accuracy for all odd values of k from 1 to 9. \n",
      "\n",
      "# https://archive.ics.uci.edu/ml/datasets/Iris\n",
      "# https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
      "# http://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/\n",
      "\n",
      "#Questions 1, 2, 4, 5 and 8 are mandatory"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy.spatial.distance as dist\n",
      "from sklearn.metrics import accuracy_score\n",
      "from collections import Counter\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import LinearSVC, SVC\n",
      "from sklearn.neighbors import KNeighborsClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Construir matriz\n",
      "data = np.array([map(float, x.split(',')[:-1]) for x in open('iris.data') if x.strip()!=''])\n",
      "labels = np.array([x.split(',')[-1].strip() for x in open('iris.data') if x.strip()!=''])\n",
      "# Cargar los datos de train y test\n",
      "iris_idx_train = np.loadtxt('iris_idx_train.txt')\n",
      "iris_idx_test = np.loadtxt('iris_idx_test.txt')\n",
      "\n",
      "iris_idx_train = iris_idx_train.astype(int)\n",
      "iris_idx_test = iris_idx_test.astype(int)\n",
      "# Datos\n",
      "iris_data_train = data[iris_idx_train,:]\n",
      "iris_data_test = data[iris_idx_test,:]\n",
      "# Etiquetas\n",
      "iris_labels_train = labels[iris_idx_train]\n",
      "iris_labels_test = labels[iris_idx_test]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# K-NN\n",
      "# Definimos una funci\u00f3n para ejecutar el clasificador K-NN con una gama de valores \"K '\n",
      "def runknn(tr_data, tr_labels, te_data, te_labels):\n",
      "    for k in range(1,9):\n",
      "        # Aqu\u00ed se utiliza la funci\u00f3n de KNN )\n",
      "        # En primer lugar, crear un objeto clasificador\n",
      "        knn = KNeighborsClassifier(k)\n",
      "        #A continuaci\u00f3n, entrenamos con los datos de entrenamiento\n",
      "        knn.fit(iris_data_train, iris_labels_train)\n",
      "        # Finalmente calculamos la exactitud de los datos de prueba\n",
      "        acc = knn.score(iris_data_test, iris_labels_test)\n",
      "        print 'Accuracy (k=%d): %.4f'%(k,acc)\n",
      "# Llamamos a la funci\u00f3n con las datos de train y test\n",
      "runknn(iris_data_train, iris_labels_train, iris_data_test, iris_labels_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy (k=1): 0.9400\n",
        "Accuracy (k=2): 0.9400\n",
        "Accuracy (k=3): 0.9400\n",
        "Accuracy (k=4): 0.9400\n",
        "Accuracy (k=5): 0.9600\n",
        "Accuracy (k=6): 0.9400\n",
        "Accuracy (k=7): 0.9600\n",
        "Accuracy (k=8): 0.9400\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# K-NN\n",
      "# Definimos una funci\u00f3n para ejecutar el clasificador K-NN con una gama de valores \"K '\n",
      "def runknn2(tr_data, tr_labels, te_data, te_labels):\n",
      "    for k in range(1,9):\n",
      "        # Crear un objeto clasificador\n",
      "        # Entrenamos con los datos de entrenamiento\n",
      "        distance=dist.cdist(tr_data, te_data)\n",
      "        k_min = np.argsort(distance.T,1)[:,1:k+1]\n",
      "        lebel_min = tr_labels [k_min]\n",
      "        #calculamos la exactitud de los datos de prueba\n",
      "        accuracy = accuracy_score(te_labels, [Counter(x).most_common()[0][0] for x in lebel_min] )\n",
      "        \n",
      "        print 'Accuracy (k=%d): %.4f'%(k,accuracy)\n",
      "# Llamamos a la funci\u00f3n con las datos de train y test\n",
      "runknn2(iris_data_train, iris_labels_train, iris_data_test, iris_labels_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy (k=1): 0.9400\n",
        "Accuracy (k=2): 0.9400\n",
        "Accuracy (k=3): 0.9400\n",
        "Accuracy (k=4): 0.9400\n",
        "Accuracy (k=5): 0.9600\n",
        "Accuracy (k=6): 0.9600\n",
        "Accuracy (k=7): 0.9600\n",
        "Accuracy (k=8): 0.9400\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}