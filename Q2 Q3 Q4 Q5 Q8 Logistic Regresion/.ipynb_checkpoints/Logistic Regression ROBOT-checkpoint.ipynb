{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#We have just finished developing the vision system of a robot waiter to work in a bar. Now we have to evaluate it.\n",
      "#Q8 After developing a french fries image logistic regression classifier for our robot waiter, we want to know how good it is. We have run the image classifier in 150.000 images, of which 150 are positives. Load the probability of french fries computed by our classifier and the true labels, and compute:\n",
      "#Accuracy and Error Rate (assume threshold is at 0.5)\n",
      "#Balanced Error Rate (implies computing True Positive Rate, True Negative Rate)\n",
      "#F1-score (implies computing also precision and recall) \n",
      "#Hint: Since we will consider the whole dataset, there is no need to sort the values.\n",
      "#Since being a bit slower is prefearable to our robot attacking a client wearing stripes, we are more concerned about precision than recall. Compute the f-beta score with beta=0.5\n",
      "#Finally, plot the precision-recall curve for our classifier.\n",
      "#Use the function precision_recall_curve found in sklearn.metrics."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import math\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import LinearSVC, SVC\n",
      "from sklearn.metrics import precision_recall_curve\n",
      "import pylab as pl\n",
      "#Use the function precision_recall_curve found in sklearn.metrics."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Datos labels scores\n",
      "labels_data =np.load (\"robot_waiter/robot_waiter_fries_labels.npy\")\n",
      "scores_data =np.load (\"robot_waiter/robot_waiter_fries_scores.npy\")\n",
      "#We have run the image classifier in 150.000 images\n",
      "data =150000\n",
      "#Accuracy and Error Rate (assume threshold is at 0.5)\n",
      "filter_scores = scores_data > 0.5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Definicion de clases\n",
      "true_positive = float(sum(filter_scores & labels_data))\n",
      "false_positive = float(sum(filter_scores & -labels_data))\n",
      "false_negative = float(sum(-filter_scores & labels_data))\n",
      "true_negative = float(sum(-filter_scores & -labels_data))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Balanced Error Rate (implies computing True Positive Rate, True Negative Rate)\n",
      "Accuracy = (true_positive+true_negative)/data\n",
      "#Error rate\n",
      "Err_Rate = (false_positive+false_negative)/data\n",
      "\n",
      "print 'Accuracy is', Accuracy\n",
      "print 'Error Rate is', Err_Rate\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy is 0.998966666667\n",
        "Error Rate is 0.00103333333333\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#F1-score (implies computing also precision and recall) \n",
      "#Hint: Since we will consider the whole dataset, there is no need to sort the values. "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precision = true_positive/(true_positive+false_positive)\n",
      "recall = true_positive/(true_positive+false_negative)\n",
      "F1_score = 2*((precision*recall)/(precision+recall))\n",
      "\n",
      "print 'F1-score is', F1_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "F1-score is 0.340425531915\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Since being a bit slower is prefearable to our robot attacking a client wearing stripes,\n",
      "#we are more concerned about precision than recall. \n",
      "#Compute the f-beta score with beta=0.5\n",
      "beta = 0.5\n",
      "f_beta = (1+beta**2)*((precision*recall)/(beta**2*precision+recall))\n",
      "\n",
      "print 'F-beta score is', f_beta\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "F-beta score is 0.408163265306\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Finally, plot the precision-recall curve for our classifier. \n",
      "#Use the function precision_recall_curve found in sklearn.metrics.\n",
      "\n",
      "precision, recall, _ = precision_recall_curve(labels_data, scores_data)\n",
      "\n",
      "pl.plot(recall, precision)\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}