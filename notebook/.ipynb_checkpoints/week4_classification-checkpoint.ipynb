{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welcome! In this notebook we will see how to use sklearn to perform classification\n",
    "# first let's import the necessary libraries:\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# sklearn is divided in several sub-libraries for the different functionality, for\n",
    "# a complete overview see the API here: http://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next let's load some data to play with. In this notebook we will use\n",
    "# the Abalone dataset from the UCI repository. The dataset should be put \n",
    "# in the same folder as the notebook. \n",
    "\n",
    "# with this dictionary we will encode the categorical feature 'gender'.\n",
    "cat_gender = {'I':np.array([1,0,0]), 'M':np.array([0,1,0]), 'F':np.array([0,0,1])}\n",
    "# loading the data and massaging it to become usable \n",
    "abalone_data = [x.strip().split(',') for x in open('abalone.data').readlines()] \n",
    "# Construct an array with the categorical feature (first one) and the remaining features\n",
    "abalone_data = np.array([np.hstack((cat_gender[x[0]],np.array(map(float,x[1:])))) for x in abalone_data])\n",
    "# Take last column as label\n",
    "abalone_labels = abalone_data[:,-1].astype('int')\n",
    "# The remaining columns are the data\n",
    "abalone_data = abalone_data[:,:-1]\n",
    "# We split the data randomly between train and test\n",
    "naba= abalone_labels.shape[0]\n",
    "sel = range(naba)\n",
    "np.random.seed(25)\n",
    "np.random.shuffle(sel)\n",
    "aba_train_data = abalone_data[sel[:naba/2],:]\n",
    "aba_train_labs = abalone_labels[sel[:naba/2]]\n",
    "aba_test_data = abalone_data[sel[naba/2:],:]\n",
    "aba_test_labs = abalone_labels[sel[naba/2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (k=1): 0.2030\n",
      "Accuracy (k=3): 0.2121\n",
      "Accuracy (k=5): 0.2437\n",
      "Accuracy (k=7): 0.2623\n",
      "Accuracy (k=9): 0.2623\n",
      "Accuracy (k=11): 0.2657\n",
      "Accuracy (k=13): 0.2666\n"
     ]
    }
   ],
   "source": [
    "# K-NN\n",
    "# We define a function to run the K-NN classifier with a range of 'k' values\n",
    "def runknn(tr_data, tr_labels, te_data, te_labels):\n",
    "    for k in range(1,15,2):\n",
    "        # Here we use the KNN function from scikit learn (in the\n",
    "        # homework you will have to implement it yourselves) \n",
    "        # First we create a classifier object\n",
    "        knn = KNeighborsClassifier(k)\n",
    "        # Then we \"train\" it with the training data\n",
    "        knn.fit(aba_train_data, aba_train_labs)\n",
    "        # Finally we compute the accuracy of the test data\n",
    "        acc = knn.score(aba_test_data, aba_test_labs)\n",
    "        print 'Accuracy (k=%d): %.4f'%(k,acc)\n",
    "# We call the function with the train and test splits\n",
    "runknn(aba_train_data, aba_train_labs, aba_test_data, aba_test_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Reg accuracy 0.244135950215\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "# Similarly as in KNN, we first create a classifier object, with C=1\n",
    "LogReg = LogisticRegression(C=1)\n",
    "# Then we train it with the training data\n",
    "LogReg.fit(aba_train_data, aba_train_labs)\n",
    "# And finally use the score function to get the accuracy\n",
    "print 'Log Reg accuracy', LogReg.score(aba_test_data, aba_test_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergi/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/sergi/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/home/sergi/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:553: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Reg with Grid search 0.258496888463 with C = 100\n"
     ]
    }
   ],
   "source": [
    "# But, is C=1 the best regularization parameter? We will\n",
    "# find out with cross-validation + grid search\n",
    "# sklearn has a handy function for that too:\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "# we define the search space for the C parameter\n",
    "parameters = {'C':[10**i for i in range(-7,7)]}\n",
    "# and create a grid search object with the type of classifier we want to\n",
    "# use and the parameters\n",
    "clf = GridSearchCV(LogisticRegression(), parameters, verbose=False)\n",
    "# and we train the classifier with grid search (this will use cross-validation\n",
    "# to select the best parameter)\n",
    "clf.fit(aba_train_data, aba_train_labs)\n",
    "print 'Log Reg with Grid search', clf.score(aba_test_data, aba_test_labs), 'with C =', clf.best_params_['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM score 0.237912876975\n",
      "Linear SVM score with Grid Search 0.238391574916 with C = 1\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Machine\n",
    "# The interface for the different classifiers is very similar; the Linear SVM\n",
    "# works in the same way as the logistic regression\n",
    "clf = LinearSVC(C=1)\n",
    "clf.fit(aba_train_data, aba_train_labs)\n",
    "print 'Linear SVM score', clf.score(aba_test_data, aba_test_labs)\n",
    "parameters = {'C':[10**i for i in range(-3, 4)]}\n",
    "clf = GridSearchCV(LinearSVC(), parameters, verbose=False)\n",
    "clf.fit(aba_train_data, aba_train_labs)\n",
    "print 'Linear SVM score with Grid Search', clf.score(aba_test_data, aba_test_labs), 'with C =', clf.best_params_['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will do the same with the kernelized SVM\n",
    "clf = SVC(C=1)\n",
    "clf.fit(aba_train_data, aba_train_labs)\n",
    "print 'RBF SVM score', clf.score(aba_test_data, aba_test_labs)\n",
    "# We can actually define several parameters we want to optimize over:\n",
    "parameters = {'C':[10**i for i in range(-3, 4)], 'kernel':['linear', 'rbf']}\n",
    "clf = GridSearchCV(SVC(), parameters, verbose=False)\n",
    "clf.fit(aba_train_data, aba_train_labs)\n",
    "print 'RBF SVM score with Grid Search', clf.score(aba_test_data, aba_test_labs), 'with C =', \\\n",
    "    parameters.best_params_['C'], 'and kernel =', parameters.best_params_['kernel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
